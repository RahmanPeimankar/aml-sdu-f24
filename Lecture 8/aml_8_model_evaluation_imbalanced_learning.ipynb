{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"img/quest/aml-logo.png\" width=\"600\"/>\n",
    "    \n",
    "***\n",
    "\n",
    "<center>Lecture 8</center>\n",
    "\n",
    "***\n",
    "\n",
    "<center>Model Evaluation <br> + <br>Learning with Imbalanced Data</center>\n",
    "\n",
    "***\n",
    "\n",
    "<center>15 April 2024<center>\n",
    "<center>Rahman Peimankar<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "* Important binary and multi-class classification metrics\n",
    "\n",
    "    1. Confusion matrix\n",
    "    2. Sensitivity & specificity\n",
    "    3. Receiver Operating Characteristic (ROC)\n",
    "    4. Area Under the Curve (AUC)\n",
    "    \n",
    "* Other metrics\n",
    "* Implementation examples\n",
    "* Metrics for regression models\n",
    "* Imbalanced data (basic approaches) \n",
    "\n",
    "    1. Random undersampling\n",
    "    2. Random oversampling\n",
    "    3. Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap of Last Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From a Raw Table of Data to a Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Here, we want to create a tree that uses **chest pain**, **good blood circulation** and **blocked artery status** to predict whether or not a patient has **heart disease**.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-11-lecture7.jpg\" width=\"1050\"/>\n",
    "</div>\n",
    "\n",
    "<font color='black'> The first thing we want to know is whether **chest pain**, **good blood circulation** and **blocked artery status** should be at the very top of our tree. (<font color='red'> **The Root Node**<font color='black'>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-34-lecture7.jpg\" width=\"900\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automatic Feature Selection Using Decison Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now, imagine if **Chest Pain** never gave us a reduction in impurity score ... <br>\n",
    "If this were the case, we would never use Chest Pain to separate the patients, and Chest Pain would not be part of our tree.\n",
    "    \n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-45-lecture7.jpg\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Even though we have data for **Chest Pain**, it is not part of our tree any more.\n",
    "* <font color='green'>This is a type of automatic feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* We could have also created large thereshold for impurity so that the reduction in impurity have to be large enough to be considered. \n",
    "* This results in simpler trees that are not **overfitted**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Missing Data in Decison Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "If overall \"yes\" occured more times than \"no\", we could put \"yes\" here!\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-48-lecture7.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Alternatively, we could find another column that has the highest correlation with blocked arteries and use that as a guide.\n",
    "* In this case, Chest Pain and Blocked Arteries are often very similar.\n",
    "    \n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-49-lecture7.png\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we had numeric data (weight) instead of Blocked Artery data, we could replace this missing value with the mean or median!<br>\n",
    "Alternatively, we could find another column that has the highest correlation with weight...\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<table><tr>\n",
    "<td>\n",
    "    \n",
    "<font size='5'>\n",
    "    \n",
    "<img src=\"img/quest/Qimage-50-lecture7.png\" width=\"500\"/>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<font size='5'>\n",
    "        \n",
    "<img src=\"img/quest/Qimage-51-lecture7.jpg\" width=\"500\"/>\n",
    "    \n",
    "</td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In this case, fitting a straight line to the data will not be very useful! <font color='red'>**Why?** \n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-59-lecture7.jpg\" width=\"500\"/>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We start by asking if the **Dosages** is less than **14.5**.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-61-lecture7.jpg\" width=\"950\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the **Dosage >= 14.5** and **Dosage >= 29**, then we are talking about these 4 observations, which have the **Average Drug effectiveness** equal to **2.5%**.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-62-lecture7.jpg\" width=\"950\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the **Dosage >= 14.5**, **Dosage < 29** and **Dosage >= 23.5** then we are talking about these 5 observations, which have the **Average Drug effectiveness** equal to **52.8%**.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-63-lecture7.jpg\" width=\"950\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lastly, if the **Dosage >= 14.5**, **Dosage < 29** and **Dosage < 23.5** then we are talking about these 4  observations, which have the **Average Drug effectiveness** equal to **100%**.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-64-lecture7.jpg\" width=\"650\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "1. Create a \"boorstrapped\" dataset\n",
    "2. Create a Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Create a decision tree using the bootstrapped dataset.\n",
    "* But only use a random subset of variables (**columns**) at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Out-Of-Bag Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We run the Out-Of-Bag sample through all of the other trees that were built without it...\n",
    "<div>\n",
    "<img src=\"img/quest/Qimage-80-lecture7.jpg\" width=\"900\"/>\n",
    "    \n",
    "* 2 trees say **NO** to Out-Of-Bag sample and 1 says **YES**\n",
    "* So the the Out-Of-Bag sample classified correctly as **NO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"25\"><center>Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Binary Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Imagine that we have a dataset to predict **Heart Disease** using different features (variables).\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-1.jpg\" width=\"650\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To achieve this we could use:\n",
    "<div>\n",
    "<center>\n",
    "<table><tr>\n",
    "<td>\n",
    "    \n",
    "**Logistic Regression**\n",
    "    \n",
    "<img src=\"img/quest/Qimage-2.jpg\" width=\"500\"/>\n",
    "    \n",
    "</td>\n",
    "<td>\n",
    "    \n",
    "**K-Nearest Neigbors**\n",
    "    \n",
    "<img src=\"img/quest/Qimage-3.jpg\" width=\"500\"/>\n",
    "    \n",
    "</td>\n",
    "    \n",
    "<td>\n",
    "    \n",
    "**Random Forest**\n",
    "    \n",
    "<img src=\"img/quest/Qimage-4.jpg\" width=\"700\"/>\n",
    "    \n",
    "</td>\n",
    "</tr></table>\n",
    "    \n",
    "Or any other methods available!\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* But how do we decide which one works best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* We divide the dataset into **Training Data** and **Testing Data**.\n",
    "* Then we **train all of the methods** that we have with the **training data**.\n",
    "* And then **test each method** on the **testing data**.\n",
    "\n",
    "Now we need to summarize how each method performs on the testing data.<br>\n",
    "<font color='green'>One way to do this is by creating the **Confsion Matrix** for each method.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<table><tr>\n",
    "<td>    \n",
    "<img src=\"img/quest/Qimage-5.jpg\" width=\"800\"/>   \n",
    "</td>\n",
    "<td>\n",
    "<img src=\"img/quest/Qimage-6.jpg\" width=\"800\"/> \n",
    "</td>   \n",
    "<td>   \n",
    "<img src=\"img/quest/Qimage-7.jpg\" width=\"800\"/> \n",
    "</td>\n",
    "</tr></table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The rows in a Confusion Matrix corresponds to what the machine learning algorithm predicted.\n",
    "* The columns correspond to the known truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1-1. True Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The top left corner contains **True Positives**.\n",
    "* These are the patients that *had heart disease* that were correctly identified by the algorithm. \n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-8.jpg\" width=\"850\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  1-2. True Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The **True Negatives** are in the bottom right-hand corner.\n",
    "* These are the patients that *did not have heat disease* that were correctly identified by the algorithm.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-9.jpg\" width=\"850\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  1-3. False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The bottom left-hand corner contains **False Negatives**.\n",
    "* **False Negatives** are when a patient has a heart disease, but the algorithm said they didn't.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-10.jpg\" width=\"850\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1-4. False Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The top right-hand corner contains the **False Positives**.\n",
    "* **False Positives** are patients that do not have heart disease, but the algorithm says they.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-11.jpg\" width=\"850\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quiz 1\n",
    "Suppose your classification model predicted true for a class which actual value was false. Then this is a\n",
    "\n",
    "A) False Positive <br>\n",
    "B) False Negative <br>\n",
    "C) True Positive <br>\n",
    "D) True Negative <br>\n",
    "\n",
    "Please answer here: https://PollEv.com/multiple_choice_polls/dFsL4CYvLLSa54GSRP2dT/respond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1-5. How to Interpret the Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The numbers along the diagonal (the <font color='green'>Green Boxes)<font color='black'> tell us how many times the samples were correctly classified.\n",
    "* The numbers *not* on the diagonal (the <font color='red'>Red Boxes)<font color='black'> are samples the algorithm messed up.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-12.jpg\" width=\"750\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can compare the **Random Forest's Confusion Matrix** to the **Confusion Matrix** we get when we use **K-Nearest Neighbors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-13.jpg\" width=\"1050\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-14.jpg\" width=\"1050\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **K-Nearest Neigbors** was worse than the **Random Forest** at predicting patients *with* Heart Disease (**107** vs **142**).\n",
    "* And worse at predicting patients *without* Heart Disease (**79** vs **110**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1-6. When We Need More Than Confusion Matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-15.jpg\" width=\"950\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* These two **Confusion Matrices** are very similar and make it hard to choose which machine learning method is a better fit for this data.\n",
    "* We will talk about more sophisticated metrices, such as **Sensitivity, Specificity, ROC** and **AUC**, that can help us make a decision in such cases later on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Sensitivity & Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-16.jpg\" width=\"850\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2-1. Sensitivity (Se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Sensitivity** tells us what percentage of patients **_with_** heart disease were correctly identified.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-17.jpg\" width=\"850\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Sensitivity**$ = \\frac{True\\,Positives}{True\\,Positives + False\\,Negatives}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2-2. Specificity (Sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Specificity** tells us what percentage of patients **_without_** heart disease were correctly identified.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-18.jpg\" width=\"750\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Specificity**$ = \\frac{True\\,Negatives}{True\\,Negatives + False\\,Positives}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2-3. Let's Calculate Se & Sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-15.jpg\" width=\"950\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-19.jpg\" width=\"650\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Sensitivity**$ = \\frac{True\\,Positives}{True\\,Positives + False\\,Negatives} = \\frac{139}{139 + 32} = 0.81$\n",
    "\n",
    "**Specificity**$ = \\frac{True\\,Negatives}{True\\,Negatives + False\\,Positives} = \\frac{112}{112 + 20} = 0.85$\n",
    "\n",
    "* **Sensitivity** tells us that **81%** of the people **_with_** Heart Disease were correctly identified by the model.\n",
    "* **Specificity** tells us that **85%** of the people **_without_** Heart Disease were correctly identified by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-20.jpg\" width=\"650\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Sensitivity**$ = \\frac{True\\,Positives}{True\\,Positives + False\\,Negatives} = \\frac{142}{142 + 29} = 0.83$\n",
    "\n",
    "**Specificity**$ = \\frac{True\\,Negatives}{True\\,Negatives + False\\,Positives} = \\frac{110}{110 + 22} = 0.83$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic Regression or Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "\n",
    "<table><tr>\n",
    "<td>\n",
    "    \n",
    "* **Sensitivity** = 0.83\n",
    "* **Specificity** = 0.83\n",
    "    \n",
    "<img src=\"img/quest/Qimage-21.jpg\" width=\"600\"/>\n",
    "    \n",
    "</td>\n",
    "<td>\n",
    "    \n",
    "* **Sensitivity** = 0.81\n",
    "* **Specificity** = 0.85\n",
    "    \n",
    "<img src=\"img/quest/Qimage-22.jpg\" width=\"600\"/>\n",
    "    \n",
    "</td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Sensitivity** tells us that the **Random Forest** is slightly better at correctly classifying *positives* cases.\n",
    "* **Specificity** tells us that the **Logistic Regression** is slightly better at correctly classifying *negatives* cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quiz 2\n",
    "With the help of a confusion matrix, we can compute\n",
    "\n",
    "A) Sensitivity <br>\n",
    "B) Precision<br>\n",
    "C) Accuracy<br>\n",
    "D) All of the above<br>\n",
    "\n",
    "Please answer here: https://PollEv.com/multiple_choice_polls/gqCnGIy2nOu8fS7DRHQLW/respond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Multi Class Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-23.jpg\" width=\"650\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* There are no single vale for **Se** and **Sp** that work for the entire matrix.\n",
    "* Instead we calculate a different **Se** and **Sp** for each fault class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. Multi Class Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-24.jpg\" width=\"650\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$Sensitivity_{Fault 1} = \\frac{True\\,Positives_{Fault 1}}{True\\,Positives_{Fault 1} + False\\,Negatives_{Fault 1}} = \\frac{12}{12 + (112 + 83)} = 0.06$\n",
    "* **Sensitivity** tells us that only **6%** of Fault 1 class were correctly identified as Fault 1 class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. Multi Class Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-25.jpg\" width=\"850\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "$Specificity{Fault 1} = \\frac{True\\,Negatives_{Fault 1}}{True\\,Negatives_{Fault 1} + False\\,Positives_{Fault 1}} = \\frac{(23+77+92+17)}{(23+77+92+17) + (102 + 93)} = 0.52$\n",
    "* **Specificity** for Fault 1 tells us that **52%** of *other* fault classes (Fault 2 and Fault 3) were correctly classified.\n",
    "* <font color='red'>**Practice**: calculate Se and Sp for other classes (Fault 2 and Fault 3)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6. Receiver Operating Characteristic (ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-26.jpg\" width=\"650\"/>\n",
    "</div>\n",
    "\n",
    "* The <font color='blue'> blue dots <font color='black'> represent <font color='blue'> obese <font color='black'> mice ...\n",
    "* The <font color='red'> red dots <font color='black'> represent mice that are <font color='red'> not obese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Now let's fit a Logistic Regression curve to the data\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-27.jpg\" width=\"550\"/>\n",
    "</div>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The y-axis is converted to the probability that a mouse <font color='blue'> is obese.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-28.jpg\" width=\"550\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The curve would tell us that there is a **high** probability that the mouse <font color='blue'> is obese.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-29.jpg\" width=\"550\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For this mouse, there is a **low** probability that the mouse <font color='blue'> is obese.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-30.jpg\" width=\"550\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6-1. Turn Probabilities into Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* One way to classify mice is to set a threshold (cutoff) at **0.5**.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-31.jpg\" width=\"550\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's evaluate the effectiveness of this Logistic Regression with the classification threshold set to **0.5**!\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-32.jpg\" width=\"550\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-33.jpg\" width=\"550\"/>\n",
    "</div>\n",
    "    \n",
    "* Now we can calculate **Se** and **Sp** to evaluate this Logistic Regression at **threshold = 0.5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6-2. New Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Since we are at the middle ot an epidemi, let assume that we would like to predict infected vs not infected individuals instead of obesity!\n",
    "* Here, it is absolutely essential to correctly classify *every* sample infected in order to minimize the risk of an outbreak... \n",
    "* So, we could lower the threshold to **0.1**.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-34.jpg\" width=\"450\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's look at the Confusion Matrix for this threshold!\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-35.jpg\" width=\"450\"/>\n",
    "</div>\n",
    "\n",
    "* On the other hand, lowering the threshold results in more **False Positives**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* What if we set the threshold higher e.g. **0.9**!\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-36.jpg\" width=\"450\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* With this data, the higher threshold does abetter job classifying samples.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-37.jpg\" width=\"550\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6-3. How do We Determine The Best Threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* We do not need to test every single threshold.\n",
    "* Some thresholds result in the exact same confusion matrix.\n",
    "\n",
    "But even if we made one confusion matrix for each threshold, it would result in a confusingly large number of confusion matrix!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-38.jpg\" width=\"850\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6-4. Why ROC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* **Receiver Operating Characteristic (ROC)** provides a simple way to summarize all of the information.\n",
    "\n",
    "<div>\n",
    "\n",
    "<table><tr>\n",
    "<td>\n",
    "    \n",
    "<img src=\"img/quest/Qimage-39.jpg\" width=\"550\"/>\n",
    "    \n",
    "</td>\n",
    "<td>\n",
    "    \n",
    "<img src=\"img/quest/Qimage-40.jpg\" width=\"550\"/>\n",
    "    \n",
    "</td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The y-axis shows the **True Positive Rate**, which is the same thing as **Sensitivity**.\n",
    "<center>True Positive Rate = Sensitivity = $\\frac{True\\, Positives}{True\\, Positives\\, +\\, False\\, Negatives}$</center>\n",
    "\n",
    "* The x-axis shows the **False Positive Rate**, which is the same thing as **1 - Specificity**.\n",
    "<center>False Positive Rate = 1 - Specificity = $\\frac{False\\, Positives}{False\\, Positives\\, +\\, True\\, Negatives}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* To get a better sense of how the **ROC** works, let's draw one from start o finish using our example data.\n",
    "* We will start by using a threshold that classifies *all* of the samples as <font color='blue'> obese <font color='black'>...\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-41.jpg\" width=\"850\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**True Positive Rate** = Sensitivity = $\\frac{True\\, Positives}{True\\, Positives\\, +\\, False\\, Negatives} = \\frac{4}{4 + 0} = 1$\n",
    "* This means that every single <font color='blue'>obese <font color='black'>sample was *correctly* classified.\n",
    "\n",
    "**False Positive Rate** = 1 - Specificity = $\\frac{False\\, Positives}{False\\, Positives\\, +\\, True\\, Negatives} = \\frac{4}{4 + 0} = 1$\n",
    "* This means that every single sample that was <font color='red'>not obese <font color='black'>was *incorrectly* classified as <font color='blue'>obese<font color='black'>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* A point at (1,1) means that even though we correctly classified **all** of the <font color='blue'>obese <font color='black'>samples, we *incorrectly* classified **all** of the samples that were <font color='red'>not obese<font color='black'>.\n",
    "* This <font color='green'> green diagonla line <font color='black'>shows where the **True Positive Rate = Fasle Positive Rate**\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-42.jpg\" width=\"650\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's change the threshold to increase it.\n",
    "* Assume that we get the below Confusion Matrix.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-43.jpg\" width=\"550\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **True Positive Rate** = Sensitivity = $\\frac{True\\, Positives}{True\\, Positives\\, +\\, False\\, Negatives} = \\frac{4}{4 + 0} = 1$\n",
    "* **False Positive Rate** = 1 - Specificity = $\\frac{False\\, Positives}{False\\, Positives\\, +\\, True\\, Negatives} = \\frac{3}{3 + 1} = 0.75$\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-44.jpg\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's increase the threshold further!\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-45.jpg\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **True Positive Rate** = Sensitivity = $\\frac{True\\, Positives}{True\\, Positives\\, +\\, False\\, Negatives} = \\frac{4}{4 + 0} = 1$\n",
    "* **False Positive Rate** = 1 - Specificity = $\\frac{False\\, Positives}{False\\, Positives\\, +\\, True\\, Negatives} = \\frac{2}{2 + 2} = 0.5$\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-46.jpg\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's increase the threshold again!\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-47.jpg\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **True Positive Rate** = Sensitivity = $\\frac{True\\, Positives}{True\\, Positives\\, +\\, False\\, Negatives} = \\frac{3}{3 + 1} = 0.75$\n",
    "* **False Positive Rate** = 1 - Specificity = $\\frac{False\\, Positives}{False\\, Positives\\, +\\, True\\, Negatives} = \\frac{1}{1 + 3} = 0.25$\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-48.jpg\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's increase the threshold again!!\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-49.jpg\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **True Positive Rate** = Sensitivity = $\\frac{True\\, Positives}{True\\, Positives\\, +\\, False\\, Negatives} = \\frac{3}{3 + 1} = 0.75$\n",
    "* **False Positive Rate** = 1 - Specificity = $\\frac{False\\, Positives}{False\\, Positives\\, +\\, True\\, Negatives} = \\frac{0}{0 + 4} = 0$\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-50.jpg\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "* This threshold resulted in no **False Positives**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's increase the threshold and plot the points! \n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-51.jpg\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If we increase the threshold to 1, it classifies all of the samples as <font color='red'>not obese <font color='black'>. \n",
    "    \n",
    "<div>\n",
    "\n",
    "<table><tr>\n",
    "<td>\n",
    "    \n",
    "<img src=\"img/quest/Qimage-52.jpg\" width=\"350\"/>\n",
    "    \n",
    "</td>\n",
    "<td>\n",
    "    \n",
    "<img src=\"img/quest/Qimage-53.jpg\" width=\"350\"/>\n",
    "    \n",
    "</td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6-5. ROC Graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Let's connect the dots, which gives us the ROC graph.\n",
    "* The ROC graph summarizes all of the confusion matrices that each threshold produced.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-54.jpg\" width=\"500\"/>\n",
    "</div>\n",
    "    \n",
    "* **Exercise**: What is/are the optimal thresholds? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 7. Area Under the Curve (AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* The **AUC** is equal to **0.9** here.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-55.jpg\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **AUC** makes it easy to compare one **ROC** curve to another.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-56.jpg\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 8. Other Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* There are other metrics that attempt to do the same thing!\n",
    "\n",
    "Precision = $\\frac{True\\, Positives}{True\\, Positives\\, +\\, False\\, Positives}$\n",
    "\n",
    "* **Precision** is the proportion of positive results that were correctly classified.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-57.jpg\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If there were lots of samples that were <font color='red'>not obese <font color='black'>relative to the number of <font color='blue'>obese <font color='black'>samples, then **Precision** might be more useful than the **False Positive Rate**.\n",
    "    \n",
    "* This is because **Precision** does not include the number of **True Negatives** in its calculation, and is not effected by the imbalance.\n",
    "    \n",
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-58.jpg\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8-1. The Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-59.jpg\" width=\"6800\"/>\n",
    "</div>\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sensitivity_and_specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 9. Implementation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48  5]\n",
      " [ 5 85]]\n",
      "0.9300699300699301\n",
      "############################################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        53\n",
      "           1       0.94      0.94      0.94        90\n",
      "\n",
      "    accuracy                           0.93       143\n",
      "   macro avg       0.93      0.93      0.93       143\n",
      "weighted avg       0.93      0.93      0.93       143\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8867924528301887"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, stratify=data.target, random_state=0)\n",
    "\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(lr.score(X_test, y_test))\n",
    "print('#'*60)\n",
    "print(classification_report(y_test, y_pred, digits=2))\n",
    "47/53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        53\n",
      "           1       1.00      0.72      0.84        90\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.84      0.86      0.82       143\n",
      "weighted avg       0.88      0.83      0.83       143\n",
      "\n",
      "############################################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        53\n",
      "           1       0.94      0.94      0.94        90\n",
      "\n",
      "    accuracy                           0.93       143\n",
      "   macro avg       0.93      0.93      0.93       143\n",
      "weighted avg       0.93      0.93      0.93       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_thresh = lr.predict_proba(X_test)[:, 1] > 0.95\n",
    "print(classification_report(y_test, y_pred_thresh))\n",
    "print('#'*60)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Please train a SVM (with default params except gamma=0.05) and a Random Forest model using the same Breast Cancer Dataset. \n",
    "# Then, plot the ROC curves of both models in a single figure and compare them. Finally, calculate AUC-ROC using \"roc_auc_score\" for both models and compare them. \n",
    "# You may also check the documnetations of the different functions mentioned here on scikit-learn to learn more about them.\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "https://www.biostat.wisc.edu/~page/rocpr.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 9-1. Multi Class Confucion Matrix Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.962\n",
      "Confusion matrix:\n",
      "[[37  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 41  0  0  0  1  1  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 43  0  0  0  0  1  1]\n",
      " [ 0  0  0  0 37  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 47  0  0  0  1]\n",
      " [ 0  1  0  0  0  0 51  0  0  0]\n",
      " [ 0  0  0  0  2  0  0 46  0  0]\n",
      " [ 0  3  1  0  0  1  0  1 42  0]\n",
      " [ 0  0  0  0  0  2  0  0  0 45]]\n",
      "0.9981863080889705\n",
      "0.999356661407736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "digits = load_digits()\n",
    "# data is between 0 and 16\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data / 16., digits.target, random_state=0)\n",
    "\n",
    "lr = LogisticRegression(multi_class='ovr').fit(X_train, y_train)\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "# pred_rf = rf.predict(X_test)\n",
    "lr_auc = roc_auc_score(y_test, lr.predict_proba(X_test), multi_class='ovo')\n",
    "rf_auc = roc_auc_score(y_test, rf.predict_proba(X_test), multi_class='ovo')\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(lr_auc)\n",
    "print(rf_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       0.91      0.95      0.93        43\n",
      "           2       0.98      1.00      0.99        44\n",
      "           3       1.00      0.96      0.98        45\n",
      "           4       0.95      0.97      0.96        38\n",
      "           5       0.92      0.98      0.95        48\n",
      "           6       0.98      0.98      0.98        52\n",
      "           7       0.96      0.96      0.96        48\n",
      "           8       0.98      0.88      0.92        48\n",
      "           9       0.96      0.96      0.96        47\n",
      "\n",
      "    accuracy                           0.96       450\n",
      "   macro avg       0.96      0.96      0.96       450\n",
      "weighted avg       0.96      0.96      0.96       450\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        37\n",
      "           1       0.95      0.98      0.97        43\n",
      "           2       1.00      0.95      0.98        44\n",
      "           3       0.94      1.00      0.97        45\n",
      "           4       1.00      0.95      0.97        38\n",
      "           5       0.94      0.98      0.96        48\n",
      "           6       1.00      1.00      1.00        52\n",
      "           7       0.96      1.00      0.98        48\n",
      "           8       1.00      0.94      0.97        48\n",
      "           9       0.98      0.94      0.96        47\n",
      "\n",
      "    accuracy                           0.97       450\n",
      "   macro avg       0.97      0.97      0.97       450\n",
      "weighted avg       0.97      0.97      0.97       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))\n",
    "print(classification_report(y_test, rf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 10. Metrics for Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Build-in standard metrics:\n",
    "\n",
    "* $R^2$  : easy to understand scale\n",
    "* MSE : easy to relate to input\n",
    "* Mean absolute error, median absolute error: more robust\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* Mean asolute percentage error (MAPE = $\\frac{100}{n}\\sum_{i=1}^n|\\frac{y-\\hat{y}}{y}|$): Absolute vs Relative "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quiz 3\n",
    "Which metric is not used for evaluating classification models?\n",
    "\n",
    "A) AUC ROC score <br>\n",
    "B) Accuracy<br>\n",
    "C) Mean absolute error<br>\n",
    "D) Prcision<br>\n",
    "\n",
    "Please answer here: https://PollEv.com/multiple_choice_polls/OlVAGTMG5bEbnlvhDrWxV/respond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"25\"><center>Learning with Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 11. Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* All data is imbalanced\n",
    "* Detect rare events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 11-1. Mammography Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "# mammography https://www.openml.org/d/310\n",
    "data = fetch_openml('mammography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11183, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X, y = data.data, data.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10923,   260], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (y.astype(np.int) + 1) // 2\n",
    "np.bincount(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fit a Model on This Mammography Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9202523350276881, 0.6335760292641773)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "\n",
    "scores = cross_validate(LogisticRegression(),\n",
    "                        X_train, y_train, cv=10,\n",
    "                        scoring=('roc_auc', 'average_precision'))\n",
    "\n",
    "scores['test_roc_auc'].mean(), scores['test_average_precision'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 11-2. Basic Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Change data:\n",
    "\n",
    "    1. Add samples\n",
    "    2. Remove samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# 11-3. Imbalance-Learn\n",
    "* https://imbalanced-learn.org/stable/\n",
    "* !pip install -U imbalanced-learn\n",
    "* An extension to scikit-learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "To resample a data sets, each sampler implements:\n",
    "\n",
    "   * data_resampled, targets_resampled = obj.resample(data, targets)\n",
    "\n",
    "Fitting and sampling can also be done in one step:\n",
    "\n",
    "   * data_resampled, targets_resampled = obj.fit_resample(data, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 11-4. Random Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* conda install -c conda-forge imbalanced-learn\n",
    "* !pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8387, 6)\n",
      "y_train: [8192  195]\n",
      "X_train_undersample: (390, 6)\n",
      "y_train_undersample: [195 195]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(replacement=False)\n",
    "X_train_subsample, y_train_subsample = rus.fit_resample(X_train, y_train)\n",
    "print('X_train: {}'.format(X_train.shape))\n",
    "print('y_train: {}'.format(np.bincount(y_train)))\n",
    "print('X_train_undersample: {}'.format(X_train_subsample.shape))\n",
    "print('y_train_undersample: {}'.format(np.bincount(y_train_subsample)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Random Undersampling Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9190187632934744, 0.5522954893068112)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "undersample_pipe = make_imb_pipeline(RandomUnderSampler(), LogisticRegressionCV())\n",
    "scores = cross_validate(undersample_pipe, X_train, y_train, cv=10, scoring=('roc_auc', 'average_precision'))\n",
    "scores['test_roc_auc'].mean(), scores['test_average_precision'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 11-5. Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8387, 6)\n",
      "y_train: [8192  195]\n",
      "X_train_oversample: (16384, 6)\n",
      "y_train_oversample: [8192 8192]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X_train_oversample, y_train_oversample = ros.fit_resample(X_train, y_train)\n",
    "print('X_train: {}'.format(X_train.shape))\n",
    "print('y_train: {}'.format(np.bincount(y_train)))\n",
    "print('X_train_oversample: {}'.format(X_train_oversample.shape))\n",
    "print('y_train_oversample: {}'.format(np.bincount(y_train_oversample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Random Oversampling Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.916433587094691, 0.5801303188497744)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversample_pipe = make_imb_pipeline(RandomOverSampler(), LogisticRegression())\n",
    "scores = cross_validate(oversample_pipe, X_train, y_train, cv=10, scoring=('roc_auc', 'average_precision'))\n",
    "scores['test_roc_auc'].mean(), scores['test_average_precision'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 11-6. Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* SMOTE is a technique that generates new observations by interpolating between observations in the dataset.<br>\n",
    "* For a given observation $x_i$, a new (synthetic) observation is generated by interpolating between one of the k-nearest neighbors, $x_{zi}$.<br>\n",
    "<center>$x_{new} = x_i + (x_{zi}x_i)$\n",
    "    \n",
    "* $\\lambda$ is a random number in the range [0,1].\n",
    "* This interpolation will create a sample on the line between $x_i$ and $x_{zi}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-62.jpg\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualization of SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"img/quest/Qimage-64.jpg\" width=\"1200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Always check roc_auc, look at curves\n",
    "* Undersampling is very fast and can help!\n",
    "* SMOTE allows adding new interpolated samples\n",
    "\n",
    "Please check the link below for more examples and methods:<br>\n",
    "https://imbalanced-learn.org/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation of SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "# Please implement a SMOTE on the previous example of Logistic Regression using \"make_imb_pipeline\".\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"25\"><center>Thank you!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
